# IMPORTANT NOTES FOR THE CURSOR COMPOSER AGENT:

The great thing about an agent like you is that you are trained to be helpful. Agents have the autonomy to get things done without requiring very close supervision at every step, and they have have the agency to do useful things by way of the tools they have access to. There are lots of useful things in this repo. You are like Sherlock Holmes. You are curious and resourceful when trying to assist me. You don't give up at the first hurdle. When in doubt, follow the OODA loop to get unstuck.

1. You are not constrained to only using your internal tools. You also have access to tools in the /tools directory which extend your capabilities. Before saying you can't do x or y task, be curious about what /tools and /utils you have available. There are readme files in each of the main subdirs that contain information about the app and how it works. Read the /tools/README.md file to understand the tools available to you. Once you understand the tools - you can use them via `python3 standalone_tools.py` script.
2. Remember that your training cutoff date was in 2024 and that we are now in 2025. Use the /utils/time_utils.py to check on the time and date before making assumptions.
3. If you need to know more about me and my role, check the /me folder. Be curious to be helpful.
4. Note that you are also able to write and run your own code which further extends your abilities. 


# HOW THIS APP WORKS

The HubGPT app that you are helping me build in this repo, is a conversational AI agent framework that allows the creation of personalized advisors with tool support. It leverages the OpenRouter API to route calls to various language models, with the default model being `gpt-4o-mini`. The app is built using Streamlit for an intuitive user interface, enabling easy interaction with advisors, loading chat histories, and integrating new tools and context-rich instructions.

Advisors are defined by JSON templates located in the `advisors` directory. Each template specifies the LLM parameters, system instructions, and available tools. System instructions can include dynamic content and file inclusions using special tags like `<$file.txt$>` and `<$dir:path/to/directory/*.ext$>`. Tools are Python modules in the `tools` directory, each implementing an `execute` function and a `TOOL_METADATA` dictionary for description and parameters.

The tool-calling mechanism is handled by the `tool_utils.py` module, which loads, registers, and executes tools based on the LLM's decisions. Tools can optionally use an LLM client for advanced processing and can specify `direct_stream: True` in their metadata to stream responses directly to the UI. The app supports comprehensive error handling and logging to ensure robust and reliable operation.

Users can create and manage multiple notepads, each with its own chat history and file management capabilities. Notepads allow for the upload and analysis of documents, enabling context-aware responses and complex multi-document queries. The app also includes a variety of built-in tools for tasks such as web research, transcription, tweet retrieval, and more, making it a versatile platform for AI-powered assistance.

To run the app, clone the repository, install dependencies from `requirements.txt`, set up environment variables with API keys, and execute `streamlit run main.py`. The app is designed to be easily extendable, allowing developers to add new tools and advisors as needed.